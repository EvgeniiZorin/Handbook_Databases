{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big data\n",
    "\n",
    "**Big data**: \n",
    "- vast, diversified amount of data growing exponentially; \n",
    "- data that cannot be stored and/or analysed by conventional methods (i.e. a single computer);\n",
    "\n",
    "**The 3 V's (or 5 V's) of Big Data**: a set of characteristics that define features and problems common to the big data.\n",
    "1. **Volume**: the amount of data;\n",
    "   1. It generally means billions or trillions of data points;\n",
    "2. **Velocity**: a measure of how quickly data arrives;\n",
    "   1. huge amounts of data are generated in a very short amount of time that needs to be processed in real-time;\n",
    "3. **Variety**: data can be structured and unstructured data;\n",
    "4. Value: we want to be able to extract some kind of value from the data we have;\n",
    "5. Veracity: how trustworthy and reliable the generated data is; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enterprise Data Storage\n",
    "\n",
    "Feature store: central repository for storing documented, curated, and access-controlled features for ML;\n",
    "\n",
    "**Databases (mostly relational)**: \n",
    "- <u>Transactional databases are generally closer to the data generation source and tend to be closer to operations</u>\n",
    "- designed to capture and record data (using OLTP)\n",
    "- live, real-time data\n",
    "- flexible data schema\n",
    "- Are the best for CRUD operations, geared towards online interactions and transactions\n",
    "- Use example: \n",
    "  - content of front page of a website is pulled from database\n",
    "  - Amazon loading and updating a list of items available to buy on their website / app\n",
    "  - *a database like this is optimised for very fast insert and update operations* - transactions;\n",
    "\n",
    "**Data Warehouse**: \n",
    "- <u>Doesn't just store the data, but also provides context, history, analysis, organisation of the data and metadata; you could say that Data Warehouse is the Database of Databases;</u>\n",
    "- Subject-oriented repository of structured data optimised for fast read.\n",
    "- Designed for analytical processing (OLAP)\n",
    "- Receives inputs from many different sources;\n",
    "- data is refreshed from source systems - stores current and historical\n",
    "- Tracks historical information - like \"how many customers or products you had 1 year ago\" and then you can do analytics on that; e.g. can capture snapshots regularly, for instance, every day\n",
    "- rigid data schema\n",
    "- Use example: \n",
    "  - *specifically designed for data analysis - storing inputs from different sources: application data, logs, telemetry;*\n",
    "  - *a data warehouse is optimised to handle very large quantities of data, but queries can take much longer to run*\n",
    "- Examples: Snowflake, Google BigQuery, Amazon Redshift, IBM Db2 Warehouse\n",
    "\n",
    "**Data Lakes**: \n",
    "- repository of data stored in its natural and raw format. \n",
    "- Designed to capture raw data (structured, unstructured)\n",
    "- A data lake can include structured data from relational databases (rows and column), semi-structured data (CSV, logs, XML, JSON), unstructured data (emails, documents, PDFs), and binary data (images, audio, video)\n",
    "- Made for large amounts of data\n",
    "- Used for ML and AI\n",
    "- can organise and put into database or data warehouses\n",
    "- Examples: AWS, Cloudera, Databricks, Google Cloud, Snowflake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "\n",
    "**Apache**: The Apache Software Foundation (ASF) exists to provide software for the public good. We believe in the power of community over code, known as The Apache Way. Thousands of people around the world contribute to ASF open source projects every day.\n",
    "\n",
    "Tools:\n",
    "- Hadoop: framework for big data storage and processing; <u>batch processing</u>\n",
    "  - Consists of two layers:\n",
    "    - Storage (HDFS): an abstraction that allows to use the storage of the cluster as if it was a single computer\n",
    "    - Processing (MapReduce)\n",
    "- Spark: framework for big data processing and analytics; \n",
    "  - Spark is a more efficient alternative to Hadoop's MapReduce\n",
    "- Hive: \n",
    "  - one of the first attempts to allow users to query data stored in Hadoop\n",
    "- Cassandra: NoSQL\n",
    "- Kafka: works with real-time data streaming; for data ingestion; \n",
    "\n",
    "---\n",
    "\n",
    "Apache Beam: a unified programming model for both batch and streaming.\n",
    "\n",
    "Key Apache Beam concepts: \n",
    "- PCollections: immutable distributed datasets\n",
    "- Transforms: operations like ParDo, GroupByKey, Combine\n",
    "- DoFns: user-defined functions for processing elements\n",
    "- Visualisation:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "You can use pandas dataframe's parameter `chunksize` to process a huge dataset\n",
    " in chunks. \n",
    "This way, you are using CPU to calculate over smaller chunks\n",
    "without having to store the entire thing in your RAM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n",
      "       'task_container_id', 'user_answer', 'answered_correctly',\n",
      "       'prior_question_elapsed_time', 'prior_question_had_explanation'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>118363</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>131167</td>\n",
       "      <td>115</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>137965</td>\n",
       "      <td>115</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>835457</td>\n",
       "      <td>2746</td>\n",
       "      <td>484</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>5382</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>39828</td>\n",
       "      <td>5382</td>\n",
       "      <td>3944</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>132189</td>\n",
       "      <td>5382</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>153727</td>\n",
       "      <td>5382</td>\n",
       "      <td>5844</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  timestamp  user_id  content_id  content_type_id  \\\n",
       "0        0          0      115        5692                0   \n",
       "1        1      56943      115        5716                0   \n",
       "2        2     118363      115         128                0   \n",
       "3        3     131167      115        7860                0   \n",
       "4        4     137965      115        7922                0   \n",
       "..     ...        ...      ...         ...              ...   \n",
       "95      95     835457     2746         484                0   \n",
       "96      96          0     5382        5000                0   \n",
       "97      97      39828     5382        3944                0   \n",
       "98      98     132189     5382         217                0   \n",
       "99      99     153727     5382        5844                0   \n",
       "\n",
       "    task_container_id  user_answer  answered_correctly  \\\n",
       "0                   1            3                   1   \n",
       "1                   2            2                   1   \n",
       "2                   0            0                   1   \n",
       "3                   3            0                   1   \n",
       "4                   4            1                   1   \n",
       "..                ...          ...                 ...   \n",
       "95                 19            0                   1   \n",
       "96                  0            0                   1   \n",
       "97                  1            1                   0   \n",
       "98                  2            0                   1   \n",
       "99                  3            1                   0   \n",
       "\n",
       "    prior_question_elapsed_time prior_question_had_explanation  \n",
       "0                           NaN                            NaN  \n",
       "1                       37000.0                          False  \n",
       "2                       55000.0                          False  \n",
       "3                       19000.0                          False  \n",
       "4                       11000.0                          False  \n",
       "..                          ...                            ...  \n",
       "95                      20000.0                           True  \n",
       "96                          NaN                            NaN  \n",
       "97                      24000.0                          False  \n",
       "98                      35000.0                          False  \n",
       "99                      88000.0                          False  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "Load only the first 100 rows\n",
    "\"\"\"\n",
    "df_100 = pd.read_csv('../train.csv', nrows=100)\n",
    "print(df_100.columns)\n",
    "df_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumed(s): 441.95269910000025\n",
      "Number of data points processed: 10,000,000\n",
      "Average of these data points: 5219.595430638324\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate average of a column\n",
    "\"\"\"\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "\n",
    "list1, counter = [], 0\n",
    "chunksize = 1000\n",
    "how_many_chunks_to_process = 10000\n",
    "\n",
    "start = timer()\n",
    "for chunk in pd.read_csv('../train.csv', chunksize=chunksize):\n",
    "    # list1.extend( chunk['content_id'].tolist() )\n",
    "    ### Instead of the line above, where we append all lines to a list\n",
    "    ### and then calculate average of everything at the end, \n",
    "    ### it is more optimal to append average of each chunk \n",
    "    ### and then at the end calculate average of averages, like in the operation below\n",
    "    list1.append( np.mean(chunk['content_id'].tolist()) )\n",
    "    ### If you want to process the entire data\n",
    "    ### simply remove the counter and break below\n",
    "    counter += 1\n",
    "    # if counter == how_many_chunks_to_process:\n",
    "    #     stop = timer()\n",
    "    #     break\n",
    "\n",
    "stop = timer()\n",
    "\n",
    "print(f\"Time consumed(s): {stop-start:,}\")\n",
    "print(f\"Number of data points processed: {chunksize*counter:,}\")\n",
    "avrg = sum(list1) / len(list1)\n",
    "print(f\"Average of these data points: {avrg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2746</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2746</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5382</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5382</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8623</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8623</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8701</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12741</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12741</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13134</td>\n",
       "      <td>0</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13134</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13134</td>\n",
       "      <td>0</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13134</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  content_type_id  count\n",
       "0       115                0     46\n",
       "1       124                0     30\n",
       "2      2746                0     19\n",
       "3      2746                1      1\n",
       "4      5382                0    125\n",
       "5      5382                1      3\n",
       "6      8623                0    109\n",
       "7      8623                1      3\n",
       "8      8701                0     17\n",
       "9     12741                0    265\n",
       "10    12741                1      6\n",
       "11    13134                0    371\n",
       "12    13134                1      5\n",
       "13    13134                0    872\n",
       "14    13134                1      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2746</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2746</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5382</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5382</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8623</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8623</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8701</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12741</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12741</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13134</td>\n",
       "      <td>0</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13134</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24418</td>\n",
       "      <td>0</td>\n",
       "      <td>6283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24418</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24600</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32421</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40828</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>40828</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44331</td>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>44331</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>45001</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>46886</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>46886</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50132</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>51285</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>53842</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>81002</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>81429</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>91216</td>\n",
       "      <td>0</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>91216</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  content_type_id  count\n",
       "0       115                0     46\n",
       "1       124                0     30\n",
       "2      2746                0     19\n",
       "3      2746                1      1\n",
       "4      5382                0    125\n",
       "5      5382                1      3\n",
       "6      8623                0    109\n",
       "7      8623                1      3\n",
       "8      8701                0     17\n",
       "9     12741                0    265\n",
       "10    12741                1      6\n",
       "11    13134                0   1243\n",
       "12    13134                1      7\n",
       "13    24418                0   6283\n",
       "14    24418                1    181\n",
       "15    24600                0     50\n",
       "16    32421                0     30\n",
       "17    40828                0     92\n",
       "18    40828                1      1\n",
       "19    44331                0    291\n",
       "20    44331                1      3\n",
       "21    45001                0     30\n",
       "22    46886                0     44\n",
       "23    46886                1      1\n",
       "24    50132                0     74\n",
       "25    51285                0     22\n",
       "26    53842                0     30\n",
       "27    81002                0     17\n",
       "28    81429                0     30\n",
       "29    91216                0    916\n",
       "30    91216                1     31"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Grouby and count by groups and subgroups\n",
    "\"\"\"\n",
    "df = pd.read_csv('../train.csv', chunksize=1000)\n",
    "counter = 0\n",
    "\n",
    "output = pd.DataFrame()\n",
    "for chunk in df:\n",
    "    categories = ['user_id', 'content_type_id']\n",
    "    details = chunk[categories]\n",
    "    details['count'] = 1\n",
    "    summary = details.groupby(categories).sum().reset_index()\n",
    "    # output = output.append(summary, ignore_index=True)\n",
    "    output = pd.concat([output, summary], ignore_index=True)\n",
    "    counter += 1\n",
    "    if counter == 10:\n",
    "        break\n",
    "\n",
    "display(output.head(15))\n",
    "\n",
    "final_output = output.groupby(categories).sum().reset_index()\n",
    "# final_output.to_csv('aggregated-information-from-big-data.csv', index=False)\n",
    "final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hadoop\n",
    "\n",
    "Hadoop is an ecosystem, or a set of technologies and tools that work together.\n",
    "\n",
    "- Has distributed processing of data which uses multiple computers to make calculations\n",
    "- Three important components of Hadoop:\n",
    "  - HDFS / Hadoop Distributed File System: used for storing data across multiple computers / servers\n",
    "  - MapReduce: helps process data in parallel\n",
    "    - this technology processes large amounts of structured and unstructured data by breaking a task into many small pieces that can be run in parallel across many servers;\n",
    "  - YARN: a resource manager and job scheduler for HDFS\n",
    "\n",
    "Limitations:\n",
    "- Relies on storing data on disk, which makes things slower\n",
    "- Processes data in batches only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark\n",
    "\n",
    "**Introduction to Spark**\n",
    "\n",
    "- Powerful tool for processing and analysing big data\n",
    "- RDD: Resilient Distributed Dataset\n",
    "- 100x faster than Hadoop\n",
    "- Manages and coordinates the execution of tasks on data across a cluster of computers\n",
    "- Components:\n",
    "  - Spark Core\n",
    "  - Spark SQL\n",
    "  - Spark Streaming\n",
    "  - Spark ML\n",
    "- Spark uses lazy evaluation\n",
    "\n",
    "https://www.youtube.com/watch?v=cZS5xYYIPzk&list=WL&index=5\n",
    "\n",
    "**PySpark Installation**\n",
    "\n",
    "`pip install pyspark`\n",
    "\n",
    "from within your conda environment: `conda install openjdk`\n",
    "\n",
    "**Some important notes**\n",
    "\n",
    "PySpark DataFrame is not the same as Pandas DataFrame\n",
    "\n",
    "directed acyclic graph (DAG) is the way Spark runs computations\n",
    "- lazy execution\n",
    "- optimization by planning ahead\n",
    "- builds a graph of transformations and applies them lasily, only when it must\n",
    "\n",
    "PySpark to Pandas\n",
    "`pd_df = df.toPandas()`\n",
    "\n",
    "Pandas to PySpark\n",
    "`spark_df = spark.createDataFrame(pd_df)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://asus-evgenii.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x20aaa56e6a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "### Initiate a Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# spark = SparkSession.builder.appName('test').getOrCreate()\n",
    "\n",
    "### Check session details\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|\n",
      "|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|\n",
      "|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|\n",
      "|       0|     3|    Moran, Mr. James|  male|28.0|    0|    0|          330877| 8.4583|       Q|\n",
      "|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|       S|\n",
      "|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|       S|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|\n",
      "|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|       C|\n",
      "|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|       S|\n",
      "|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|       S|\n",
      "|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|       S|\n",
      "|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|       S|\n",
      "|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|       S|\n",
      "|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|       S|\n",
      "|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|       Q|\n",
      "|       1|     2|Williams, Mr. Cha...|  male|28.0|    0|    0|          244373|   13.0|       S|\n",
      "|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|       S|\n",
      "|       1|     3|Masselmani, Mrs. ...|female|28.0|    0|    0|            2649|  7.225|       C|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Survived', 'int'),\n",
       " ('Pclass', 'int'),\n",
       " ('Name', 'string'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'double'),\n",
       " ('SibSp', 'int'),\n",
       " ('Parch', 'int'),\n",
       " ('Ticket', 'string'),\n",
       " ('Fare', 'double'),\n",
       " ('Embarked', 'string')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Read data\n",
    "\n",
    "### Option 1: reads all columns as string\n",
    "df = spark.read.csv(\n",
    "    'clean_titanic_data.csv', \n",
    "    header=True,\n",
    "    inferSchema=True, # get PySpark to infer the data schema by itself\n",
    "    nullValue='NA' # Replace null values with another value\n",
    ")\n",
    "# df = spark.read.option('header', 'true').csv('clean_titanic_data.csv')\n",
    "### You can also specify data schema\n",
    "# schema = 'Age INTEGER, Sex STRING, ChestPainType STRING'\n",
    "# df = spark.read.csv('name.csv', schema=schema, header=True)\n",
    "\n",
    "### Saving data\n",
    "### Cannot overwrite\n",
    "# df.write.format('csv').save('path/to/save/output.csv')\n",
    "### Overwrite if exists\n",
    "# df.write.format('csv').mode('overwrite').save('path/to/save/output.csv')\n",
    "\n",
    "df.show()\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------+\n",
      "|summary|               Age|   Sex|\n",
      "+-------+------------------+------+\n",
      "|  count|               891|   891|\n",
      "|   mean| 29.36158249158249|  NULL|\n",
      "| stddev|13.019696550973201|  NULL|\n",
      "|    min|              0.42|female|\n",
      "|    max|              80.0|  male|\n",
      "+-------+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Summary statistics\n",
    "df.select(['Age', 'Sex']).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Show column data types\n",
    "df.dtypes\n",
    "df.printSchema()\n",
    "### Change column data type\n",
    "# df = df.withColumn('Age', df.Age.cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+\n",
      "|                Name|\n",
      "+--------------------+\n",
      "|Braund, Mr. Owen ...|\n",
      "|Cumings, Mrs. Joh...|\n",
      "|Heikkinen, Miss. ...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+------+\n",
      "|                Name|   Sex|\n",
      "+--------------------+------+\n",
      "|Braund, Mr. Owen ...|  male|\n",
      "|Cumings, Mrs. Joh...|female|\n",
      "|Heikkinen, Miss. ...|female|\n",
      "+--------------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Remove column\n",
    "# df.drop('Age')\n",
    "### Rename column\n",
    "# df.withColumnRenamed('Age', 'age')\n",
    "### Rename multiple columns\n",
    "# name_pairs = [('Age', 'age'), ('Sex', 'sex')]\n",
    "# for old_name, new_name in name_pairs:\n",
    "#     df = df.withColumnRenamed(old_name, new_name)\n",
    "\n",
    "### Show the number of rows\n",
    "df.count()\n",
    "### Show first few rows of a table\n",
    "df.show(3)\n",
    "### Only for selected columns\n",
    "df.select('Name').show(3)\n",
    "df.select(['Name', 'Sex']).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|\n",
      "|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|\n",
      "|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|\n",
      "|       0|     3|    Moran, Mr. James|  male|28.0|    0|    0|          330877| 8.4583|       Q|\n",
      "|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|       S|\n",
      "|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|       S|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|\n",
      "|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|       C|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|\n",
      "|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|\n",
      "|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|\n",
      "|       0|     3|    Moran, Mr. James|  male|28.0|    0|    0|          330877| 8.4583|       Q|\n",
      "|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|       S|\n",
      "|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|       S|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|\n",
      "|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|       C|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "5         0       3                                   Moran, Mr. James   \n",
       "6         0       1                            McCarthy, Mr. Timothy J   \n",
       "7         0       3                     Palsson, Master. Gosta Leonard   \n",
       "8         1       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   \n",
       "9         1       2                Nasser, Mrs. Nicholas (Adele Achem)   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250        S  \n",
       "3  female  35.0      1      0            113803  53.1000        S  \n",
       "4    male  35.0      0      0            373450   8.0500        S  \n",
       "5    male  28.0      0      0            330877   8.4583        Q  \n",
       "6    male  54.0      0      0             17463  51.8625        S  \n",
       "7    male   2.0      3      1            349909  21.0750        S  \n",
       "8  female  27.0      0      2            347742  11.1333        S  \n",
       "9  female  14.0      1      0            237736  30.0708        C  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SQL\n",
    "df.createOrReplaceTempView('df') # add the table to the database catalog\n",
    "df_top10 = spark.sql('SELECT * FROM df LIMIT 10')\n",
    "df_top10.show()\n",
    "\n",
    "spark.sql(\"SELECT * FROM df LIMIT 10\").show()\n",
    "\n",
    "# Can later convert the result of the query to a dataframe\n",
    "tips10_df = df_top10.toPandas()\n",
    "tips10_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Pclass|count|\n",
      "+------+-----+\n",
      "|     1|  216|\n",
      "|     3|  491|\n",
      "|     2|  184|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### count\n",
    "df.groupby('Pclass').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+\n",
      "|Pclass|female|male|\n",
      "+------+------+----+\n",
      "|     3|   144| 347|\n",
      "|     1|    94| 122|\n",
      "|     2|    76| 108|\n",
      "+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Pivoting\n",
    "df.groupby('Pclass').pivot('Sex').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|\n",
      "|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|       S|\n",
      "|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|       S|\n",
      "|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|       S|\n",
      "|       1|     3|Masselmani, Mrs. ...|female|28.0|    0|    0|            2649|  7.225|       C|\n",
      "|       1|     3|\"McGowan, Miss. A...|female|15.0|    0|    0|          330923| 8.0292|       Q|\n",
      "|       0|     3|Palsson, Miss. To...|female| 8.0|    3|    1|          349909| 21.075|       S|\n",
      "|       1|     3|Asplund, Mrs. Car...|female|38.0|    1|    5|          347077|31.3875|       S|\n",
      "|       1|     3|\"O'Dwyer, Miss. E...|female|28.0|    0|    0|          330959| 7.8792|       Q|\n",
      "|       1|     3|Glynn, Miss. Mary...|female|28.0|    0|    0|          335677|   7.75|       Q|\n",
      "|       0|     3|Vander Planke, Mi...|female|18.0|    2|    0|          345764|   18.0|       S|\n",
      "|       1|     3|Nicola-Yarred, Mi...|female|14.0|    1|    0|            2651|11.2417|       C|\n",
      "|       0|     3|Ahlin, Mrs. Johan...|female|40.0|    1|    0|            7546|  9.475|       S|\n",
      "|       1|     3|Devaney, Miss. Ma...|female|19.0|    0|    0|          330958| 7.8792|       Q|\n",
      "|       1|     3|O'Driscoll, Miss....|female|28.0|    0|    0|           14311|   7.75|       Q|\n",
      "|       0|     3|Arnold-Franchi, M...|female|18.0|    1|    0|          349237|   17.8|       S|\n",
      "|       1|     3|Andersson, Miss. ...|female|17.0|    4|    2|         3101281|  7.925|       S|\n",
      "|       0|     3|Goodwin, Miss. Li...|female|16.0|    5|    2|         CA 2144|   46.9|       S|\n",
      "|       1|     3|Dowdell, Miss. El...|female|30.0|    0|    0|          364516| 12.475|       S|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Filtering\n",
    "\n",
    "### many interchangeable options\n",
    "df.filter('age > 18')\n",
    "df.where('age > 18')\n",
    "df.where(df['age'] > 18)\n",
    "### Use AND (&) or OR (|) operators\n",
    "df.where((df['age'] > 18) & (df['sex'] == 'male'))\n",
    "### Rows that do NOT meet the criteria\n",
    "df.filter(~(df['Sex'] == 'male'))\n",
    "\n",
    "df_03 = df.filter(df.Sex == 'female').filter(df.Pclass == 3)\n",
    "df_03.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+---------------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|survived_pclass|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+---------------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|              0|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|              1|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|              3|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Evaluating a string\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "survived_pclass = 'Survived * Pclass + 0'\n",
    "df.withColumn('survived_pclass', expr(survived_pclass)).show(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with null values: \n",
    "\n",
    "```py\n",
    "### drop all rows that contain a single null value\n",
    "df = df.na.drop()\n",
    "### drop rows that has all null values\n",
    "df = df.na.drop(how='all')\n",
    "### drop rows that has the number of null values exceeding a specified threshold\n",
    "df = df.na.drop(thresh=2)\n",
    "### drop null values for specified columns only\n",
    "df = df.na.drop(how='any', subset=['age', 'sex'])\n",
    "### replace null values with a specified value\n",
    "df = df.na.fill(value='?', subset=['sex'])\n",
    "\n",
    "### Using imputer strategy\n",
    "from pyspark.ml.feature import Imputer\n",
    "imptr = Imputer(inputCols=['age', 'RestingBP'],\n",
    "                outputCols=['age', 'RestingBP']).setStrategy('mean')\n",
    "df = imptr.fit(df).transform(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|   Sex|          avg(Age)|\n",
      "+------+------------------+\n",
      "|female|27.929936305732483|\n",
      "|  male| 30.14067590987868|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Sex').agg({'Age': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|   Sex|          avg(Age)|\n",
      "+------+------------------+\n",
      "|  male| 30.14067590987868|\n",
      "|female|27.929936305732483|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "df.groupby('Sex').agg({'Age': 'mean'}).orderBy(desc('avg(Age)')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----------------+\n",
      "|   Sex|min(Age)|      avg(Pclass)|\n",
      "+------+--------+-----------------+\n",
      "|female|    0.75|2.159235668789809|\n",
      "|  male|    0.42|2.389948006932409|\n",
      "+------+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df.groupby('Sex').agg(F.min(df['Age']), F.avg(df['Pclass'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Machine Learning with spark\n",
    "# pyspark won't accept a table of feature column, but \n",
    "# needs a vector of feature columns\n",
    "\n",
    "X_column_names = ['Age', 'SibSp']\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "df = df.withColumn('Age', df.Age.cast(FloatType()))\n",
    "df = df.withColumn('SibSp', df.SibSp.cast(FloatType()))\n",
    "df = df.withColumn('Survived', df.Survived.cast(FloatType()))\n",
    "v_asmblr = VectorAssembler(inputCols=X_column_names, outputCol='Fvec')\n",
    "df = v_asmblr.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression(featuresCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFvec\u001b[39m\u001b[38;5;124m'\u001b[39m, labelCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrainset\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mcoefficients, model\u001b[38;5;241m.\u001b[39mintercept)\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(testset)\u001b[38;5;241m.\u001b[39mpredictions\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainset' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "model = LinearRegression(featuresCol='Fvec', labelCol='Survived')\n",
    "model = model.fit(trainset)\n",
    "print(model.coefficients, model.intercept)\n",
    "\n",
    "model.evaluate(testset).predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
